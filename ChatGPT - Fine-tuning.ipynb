{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OpenAI - Fine-tuning a ChatGPT Model on custom dataset</h2>\n",
    "\n",
    "Here, we have a dataset for customer support tickets which consists of emails and ticket types. We want to predict the support ticket type by analysing the email content.\n",
    "\n",
    "The <a>customer_support_tickets.csv</a> file was downloaded from [here.](https://www.kaggle.com/datasets/suraj520/customer-support-ticket-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Explore the data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'critical', 1: 'low'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>customer_email</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>ticket_subject</th>\n",
       "      <th>ticket_description</th>\n",
       "      <th>product_purchased</th>\n",
       "      <th>date_of_purchase</th>\n",
       "      <th>ticket_priority</th>\n",
       "      <th>ticket_type_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marisa Obrien</td>\n",
       "      <td>carrollallison@example.com</td>\n",
       "      <td>critical</td>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>GoPro Hero</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica Rios</td>\n",
       "      <td>clarkeashley@example.com</td>\n",
       "      <td>critical</td>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>LG Smart TV</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Robbins</td>\n",
       "      <td>gonzalestracy@example.com</td>\n",
       "      <td>low</td>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Dell XPS</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christina Dillon</td>\n",
       "      <td>bradleyolson@example.org</td>\n",
       "      <td>low</td>\n",
       "      <td>Account access</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Microsoft Office</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander Carroll</td>\n",
       "      <td>bradleymark@example.com</td>\n",
       "      <td>low</td>\n",
       "      <td>Data loss</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Autodesk AutoCAD</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_name              customer_email ticket_type  \\\n",
       "0        Marisa Obrien  carrollallison@example.com    critical   \n",
       "1         Jessica Rios    clarkeashley@example.com    critical   \n",
       "2  Christopher Robbins   gonzalestracy@example.com         low   \n",
       "3     Christina Dillon    bradleyolson@example.org         low   \n",
       "4    Alexander Carroll     bradleymark@example.com         low   \n",
       "\n",
       "             ticket_subject  \\\n",
       "0             Product setup   \n",
       "1  Peripheral compatibility   \n",
       "2           Network problem   \n",
       "3            Account access   \n",
       "4                 Data loss   \n",
       "\n",
       "                                  ticket_description product_purchased  \\\n",
       "0  I'm having an issue with the {product_purchase...        GoPro Hero   \n",
       "1  I'm having an issue with the {product_purchase...       LG Smart TV   \n",
       "2  I'm facing a problem with my {product_purchase...          Dell XPS   \n",
       "3  I'm having an issue with the {product_purchase...  Microsoft Office   \n",
       "4  I'm having an issue with the {product_purchase...  Autodesk AutoCAD   \n",
       "\n",
       "  date_of_purchase ticket_priority ticket_type_category  \n",
       "0       2021-03-22        Critical                    0  \n",
       "1       2021-05-22        Critical                    0  \n",
       "2       2020-07-14             Low                    1  \n",
       "3       2020-11-13             Low                    1  \n",
       "4       2020-02-04             Low                    1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('customer_support_tickets.csv')\n",
    "\n",
    "df.dropna(subset=['Ticket Description', 'Ticket Type', 'Ticket Priority'], inplace=True)\n",
    "\n",
    "df = df[['Customer Name', 'Customer Email', 'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Product Purchased', 'Date of Purchase', 'Ticket Priority']]\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "# df['ticket_type'] = df['ticket_type'].str.replace(' ', '_').str.lower()\n",
    "df['ticket_type'] = df['ticket_priority'].str.replace(' ', '_').str.lower()\n",
    "df = df[df['ticket_type'].isin(['low', 'critical'])]\n",
    "\n",
    "# create new column for ticket type category and set numierical value for each category\n",
    "df['ticket_type_category'] = df['ticket_type'].astype('category').cat.codes.astype(str)\n",
    "# print all unique category and code mapping\n",
    "print(dict(enumerate(df['ticket_type'].astype('category').cat.categories)))\n",
    "\n",
    "# df.groupby('ticket_type').count()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Prepare the data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ticket_description'] = df.apply(lambda row: row['ticket_description'].replace(\"###\", ''), axis=1)\n",
    "# df['ticket_description'] = df.apply(lambda row: row['ticket_description'].replace(\"{product_purchased}\", row['product_purchased']), axis=1)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['prompt'] =  \"Subject:\" + df['ticket_subject'] + \"\\nFrom:\" + df['customer_name'] + \"<\" + df['customer_email'] + \">\\nDate:\" + df['date_of_purchase'] + \"\\nContent:\" + df['ticket_description'] #+ \"\\n\\n###\\n\\n\"\n",
    "df['completion'] = df['ticket_type_category']#.apply(lambda x: ' ' + str(x))\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# get 100 random samples for each ticket_type and shuffle the data\n",
    "df = df.groupby('completion').apply(lambda x: x.sample(n=625, random_state=42)).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the prompt + completion doesn't exceed 2048 tokens, including the separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the prompt and completion\n",
    "def calculate_token_length(row):\n",
    "    return len(encoding.encode(row['prompt'])) + len(encoding.encode(row['completion']))\n",
    "\n",
    "df['token_length'] = df.apply(calculate_token_length, axis=1)\n",
    "\n",
    "df = df[df['token_length'] <= 2048]\n",
    "\n",
    "df = df[['prompt', 'completion']]\n",
    "df.to_json('dataset.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Prepare the custom dataset using openAI tool</h4> \n",
    "The CLI command: <code>`openai tools fine_tunes.prepare_data -f [TRAINING_FILE_NAME] </code>\n",
    "\n",
    "This command will guide through the steps in validating your data, gives suggestions and reformats it.\n",
    "\n",
    "We additionally specify `-q` which auto-accepts all suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sankalp/Documents/workspace/email_classification/.venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 1250 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- All prompts start with prefix `Subject:`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `dataset_prepared_train.jsonl` and `dataset_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"dataset_prepared_train.jsonl\" -v \"dataset_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" 1\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
      "Once your model starts training, it'll approximately take 32.33 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f dataset.jsonl  -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Fine-Tune the model</h4>\n",
    "\n",
    "The tool suggests to add `--compute_classification_metrics --classification_n_classes 5` as it is a multi-classification. In case of binary classification you need to add `--classification_positive_class <label>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sankalp/Documents/workspace/email_classification/.venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Found potentially duplicated files with name 'dataset_prepared_train.jsonl', purpose 'fine-tune' and size 430137 bytes\n",
      "file-dKpIuthuNRKVQGBwH0D5v3Kn\n",
      "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# !openai api fine_tunes.create -t \"dataset_prepared_train.jsonl\" -v \"dataset_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 3 -m ada\n",
    "!openai api fine_tunes.create -t \"dataset_prepared_train.jsonl\" -v \"dataset_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 2 --classification_positive_class \" 0\" -m ada --n_epochs 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've started a fine-tune job, it may take some time to complete. If the event stream is interrupted for any reason, you can resume it by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sankalp/Documents/workspace/email_classification/.venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[2023-06-17 22:22:45] Created fine-tune: ft-WmyiGqKm3uop96kRlMfKJG8z\n",
      "[2023-06-17 22:24:57] Fine-tune costs $6.38\n",
      "[2023-06-17 22:24:58] Fine-tune enqueued. Queue number: 0\n",
      "[2023-06-17 22:24:59] Fine-tune started\n",
      "[2023-06-17 22:35:46] Completed epoch 1/2\n",
      "[2023-06-17 22:45:04] Uploaded model: davinci:ft-personal-2023-06-17-17-15-03\n",
      "[2023-06-17 22:45:05] Uploaded result file: file-RsKkJTKvZJltASH15ji21SWM\n",
      "[2023-06-17 22:45:05] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m davinci:ft-personal-2023-06-17-17-15-03 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-WmyiGqKm3uop96kRlMfKJG8z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Results and expected model performance</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sankalp/Documents/workspace/email_classification/.venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.results -i ft-WmyiGqKm3uop96kRlMfKJG8z > result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>elapsed_tokens</th>\n",
       "      <th>elapsed_examples</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_sequence_accuracy</th>\n",
       "      <th>training_token_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_sequence_accuracy</th>\n",
       "      <th>validation_token_accuracy</th>\n",
       "      <th>classification/accuracy</th>\n",
       "      <th>classification/precision</th>\n",
       "      <th>classification/recall</th>\n",
       "      <th>classification/auroc</th>\n",
       "      <th>classification/auprc</th>\n",
       "      <th>classification/f1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1001</td>\n",
       "      <td>229794</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.017348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>0.468847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  elapsed_tokens  elapsed_examples  training_loss  \\\n",
       "1000  1001          229794              2002       0.013592   \n",
       "\n",
       "      training_sequence_accuracy  training_token_accuracy  validation_loss  \\\n",
       "1000                         0.5                      0.5         0.017348   \n",
       "\n",
       "      validation_sequence_accuracy  validation_token_accuracy  \\\n",
       "1000                           0.0                        0.0   \n",
       "\n",
       "      classification/accuracy  classification/precision  \\\n",
       "1000                    0.524                       0.0   \n",
       "\n",
       "      classification/recall  classification/auroc  classification/auprc  \\\n",
       "1000                    0.0              0.484091              0.468847   \n",
       "\n",
       "      classification/f1.0  \n",
       "1000                  0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('result.csv')\n",
    "results[results['classification/accuracy'].notnull()].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('dataset_prepared_valid.jsonl', lines=True)\n",
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy reaches 52.4%. This is same as that of scikit-learn models (see [here](https://github.com/sankalptambe/openai-model-ada-fine-tuned/blob/main/Comparing%20ChatGPT%20with%20sklearn%20models.ipynb)). \n",
    "\n",
    "The Ada model expects `~500` samples/category for good results (52.4% is due to the shitty dataset. It is used just to compare the model performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['classification/accuracy'].notnull()]['classification/accuracy'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using the model</h4>\n",
    "\n",
    "We can now call the model to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "ft_model = 'ada:ft-personal-2023-06-17-10-47-01'\n",
    "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][1] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0)\n",
    "print('Actual value: ' + str(test['completion'][1]))\n",
    "res['choices'][0]['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the log probabilities, we can specify logprobs parameter on the completion request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][0] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
    "res['choices'][0]['logprobs']['top_logprobs'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By requesting log_probs, we can see the prediction (log) probability for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
